# ðŸ“‹ Implementation Plan â€” AgentHelm v0.3.0 (DSPy + Multi-Agent)

> **Branch**: `v0.3.0-dspy-multiagent`
> **Phase**: 1 of 4
> **Duration**: 4-6 weeks
> **Goal**: DSPy-native agents, unified memory hub, multi-agent orchestration, CLI

---

## Week 1: Project Setup & AgentHelm Core Port

### 1.1 Repository Setup
- [ ] Checkout branch `v0.3.0-dspy-multiagent` (already done!)
- [ ] Update `pyproject.toml` with new dependencies:
  ```toml
  [project]
  name = "agenthelm"
  version = "0.3.0"
  requires-python = ">=3.11"
  dependencies = [
      "dspy-ai>=2.5",
      "pydantic>=2.0",
      "redis>=5.0",
      "chromadb>=0.4",
      "opentelemetry-api>=1.20",
      "opentelemetry-sdk>=1.20",
      "click>=8.0",  # CLI
      "rich>=13.0",  # Pretty output
  ]
  ```
- [ ] Set up pre-commit hooks (ruff, mypy)
- [ ] Create `README.md`, `LICENSE`, `CONTRIBUTING.md`
- [ ] Set up GitHub Actions for CI (lint, test)

### 1.2 Port AgentHelm Core (The DNA)

These components are **directly ported** from AgentHelm with minimal changes:

```
agenthelm/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tool.py              # @tool decorator + TOOL_REGISTRY (from AgentHelm)
â”‚   â”œâ”€â”€ event.py             # ExecutionEvent model (enhanced)
â”‚   â”œâ”€â”€ tracer.py            # ExecutionTracer (from AgentHelm)
â”‚   â”œâ”€â”€ handlers.py          # ApprovalHandler, CliHandler (from AgentHelm)
â”‚   â”œâ”€â”€ cost.py              # NEW: CostTracker, TokenUsage
â”‚   â””â”€â”€ storage/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py          # BaseStorage ABC (from AgentHelm)
â”‚       â”œâ”€â”€ json_storage.py  # JSON file storage (from AgentHelm)
â”‚       â””â”€â”€ sqlite_storage.py # SQLite storage (from AgentHelm)
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # Agent base class (NEW: DSPy-native)
â”‚   â””â”€â”€ registry.py          # Agent registry
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hub.py               # MemoryHub
â”‚   â”œâ”€â”€ context.py           # MemoryContext (per-session)
â”‚   â”œâ”€â”€ short_term.py        # ShortTermMemory
â”‚   â””â”€â”€ semantic.py          # SemanticMemory
â””â”€â”€ config.py                # Configuration management
```

### 1.3 Enhanced Tool Contract (Ported + Extended)

```python
# nexus/core/tool.py â€” Ported from AgentHelm

@tool(
    inputs={"file_path": "str"},
    outputs={"content": "str"},
    side_effects=["file:read"],
    max_cost=0.01,                    # Cost budget
    requires_approval=True,           # Human gate
    retries=3,                        # Auto-retry
    compensating_tool="delete_file",  # Rollback action
    timeout=30.0,                     # NEW: Timeout in seconds
    tags=["io", "filesystem"],        # NEW: For filtering/discovery
)
def read_file(file_path: str) -> str:
    ...
```

### 1.4 Enhanced Execution Event (Ported + Extended)

```python
# nexus/core/event.py â€” Ported from AgentHelm

class ExecutionEvent(BaseModel):
    # From AgentHelm
    timestamp: datetime
    tool_name: str
    inputs: dict[str, Any]
    outputs: dict[str, Any]
    execution_time: float
    error_state: Optional[str]
    llm_reasoning_trace: str
    confidence_score: float
    
    # NEW: Enhanced tracking
    token_usage: Optional[TokenUsage] = None
    estimated_cost_usd: float = 0.0
    retry_count: int = 0
    agent_name: Optional[str] = None   # Which agent executed this
    session_id: Optional[str] = None   # Session context
    trace_id: Optional[str] = None     # OpenTelemetry trace ID
```

### 1.5 Cost Tracker (NEW)

```python
# nexus/core/cost.py â€” NEW component

class TokenUsage(BaseModel):
    input_tokens: int
    output_tokens: int
    model: str

# Model pricing (USD per 1K tokens)
MODEL_PRICING = {
    "gpt-4o": {"input": 0.005, "output": 0.015},
    "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
    "claude-3-5-sonnet": {"input": 0.003, "output": 0.015},
    "mistral-large": {"input": 0.002, "output": 0.006},
    # ... more models
}

class CostTracker:
    def __init__(self):
        self.total_cost = 0.0
        self.events: list[TokenUsage] = []
    
    def track(self, usage: TokenUsage) -> float:
        cost = self._calculate_cost(usage)
        self.total_cost += cost
        self.events.append(usage)
        return cost
    
    def check_budget(self, max_cost: float) -> bool:
        return self.total_cost < max_cost
```

**Week 1 Deliverables:**
- âœ… Repository initialized with CI/CD
- âœ… `@tool` decorator ported from AgentHelm
- âœ… `ExecutionTracer` ported with rollback support
- âœ… `ApprovalHandler` hierarchy ported
- âœ… Storage backends ported (JSON, SQLite)
- âœ… NEW: `CostTracker` with model pricing
- âœ… NEW: Enhanced `ExecutionEvent` with cost tracking
- âœ… Unit tests for all ported components

---

## Week 2: Memory Hub Implementation

### 2.1 Short-Term Memory (Redis-backed)
```python
# agenthelm/memory/short_term.py
class ShortTermMemory:
    """Fast key-value store for session context."""
    
    def __init__(self, backend_url: str = "redis://localhost:6379"):
        ...
    
    async def read(self, key: str) -> Any: ...
    async def write(self, key: str, value: Any, ttl: int = 3600): ...
    async def delete(self, key: str): ...
    async def list_keys(self, prefix: str) -> list[str]: ...
```

### 2.2 Semantic Memory (ChromaDB-backed)
```python
# agenthelm/memory/semantic.py
class SemanticMemory:
    """Vector store for similarity search."""
    
    def __init__(self, backend_path: str = "./nexus_vectors"):
        ...
    
    async def add(self, id: str, text: str, metadata: dict = None): ...
    async def search(self, query: str, top_k: int = 5) -> list[MemoryMatch]: ...
    async def delete(self, id: str): ...
```

### 2.3 Memory Context (Agent Interface)
```python
# agenthelm/memory/context.py
class MemoryContext:
    """Per-session context for agents to interact with memory."""
    
    def __init__(self, session_id: str, hub: MemoryHub):
        self.session_id = session_id
        self.hub = hub
    
    # Short-term ops (sync for DSPy compatibility)
    def read(self, key: str) -> Any: ...
    def write(self, key: str, value: Any): ...
    
    # Semantic ops
    def remember(self, text: str, metadata: dict = None): ...
    def recall(self, query: str, top_k: int = 5) -> list[str]: ...
    
    # Cross-agent shared state
    def get_shared(self, key: str) -> Any: ...
    def set_shared(self, key: str, value: Any): ...
```

**Deliverables:**
- Working `ShortTermMemory` with Redis
- Working `SemanticMemory` with ChromaDB
- `MemoryContext` that agents use for all memory ops
- Unit tests for all memory operations

---

## Week 3: DSPy Agent Integration

### 3.1 Agent Base Class
```python
# agenthelm/agent/base.py
import dspy
from nexus.memory import MemoryContext

class Agent(dspy.Module):
    """Base class for all Nexus agents."""
    
    def __init__(self, name: str, description: str = ""):
        super().__init__()
        self.name = name
        self.description = description
    
    def forward(self, context: MemoryContext, **kwargs):
        """Override in subclass. Context provides memory access."""
        raise NotImplementedError
    
    def get_signature(self) -> dict:
        """Return agent's input/output signature for discovery."""
        ...
```

### 3.2 Example Agents
```python
# nexus/agents/examples.py
class ResearcherAgent(Agent):
    """Researches a topic and stores findings in memory."""
    
    class Signature(dspy.Signature):
        topic: str = dspy.InputField()
        findings: str = dspy.OutputField()
        sources: list[str] = dspy.OutputField()
    
    def __init__(self):
        super().__init__(name="researcher", description="Research any topic")
        self.research = dspy.ChainOfThought(self.Signature)
    
    def forward(self, context: MemoryContext, topic: str):
        # Pull any relevant context from memory
        prior_knowledge = context.recall(topic, top_k=3)
        
        # Run DSPy module
        result = self.research(topic=topic, prior_knowledge=prior_knowledge)
        
        # Store findings in memory for other agents
        context.write("latest_research", result.findings)
        context.remember(result.findings, metadata={"agent": self.name})
        
        return result
```

### 3.3 Agent Registry
```python
# nexus/agent/registry.py
class AgentRegistry:
    """Central registry for discovering available agents."""
    
    _agents: dict[str, Agent] = {}
    
    @classmethod
    def register(cls, agent: Agent): ...
    
    @classmethod
    def get(cls, name: str) -> Agent: ...
    
    @classmethod
    def list_all(cls) -> list[dict]: ...  # Returns signatures
```

**Deliverables:**
- `Agent` base class integrating DSPy + MemoryContext
- 2-3 example agents (Researcher, Writer, Reviewer)
- Agent registry for discovery
- Unit tests for agent execution with mocked LLM

---

## Week 4: Basic Orchestration

### 4.1 Sequential Pipeline
```python
# nexus/orchestration/pipeline.py
class Pipeline:
    """Execute agents sequentially, passing context through."""
    
    def __init__(self, agents: list[Agent]):
        self.agents = agents
    
    async def run(self, context: MemoryContext, initial_input: dict) -> dict:
        result = initial_input
        for agent in self.agents:
            result = agent.forward(context, **result)
        return result
```

### 4.2 Parallel Execution
```python
# nexus/orchestration/parallel.py
class Parallel:
    """Execute agents concurrently, merge results."""
    
    def __init__(self, agents: list[Agent], merge_strategy: str = "dict"):
        self.agents = agents
        self.merge_strategy = merge_strategy
    
    async def run(self, context: MemoryContext, input: dict) -> dict:
        tasks = [agent.forward(context, **input) for agent in self.agents]
        results = await asyncio.gather(*tasks)
        return self._merge(results)
```

### 4.3 Orchestrator Wrapper
```python
# nexus/orchestration/__init__.py
class Orchestrator:
    """High-level orchestration interface."""
    
    def __init__(self, memory_hub: MemoryHub):
        self.memory_hub = memory_hub
    
    async def run_pipeline(self, agents: list[Agent], task: str) -> dict:
        context = self.memory_hub.create_context()
        context.write("task", task)
        pipeline = Pipeline(agents)
        return await pipeline.run(context, {"task": task})
```

### 4.4 Saga Pattern / Rollback (From AgentHelm DNA)

**This is a key AgentHelm feature** â€” automatic rollback when a step fails:

```python
# nexus/orchestration/saga.py
class SagaOrchestrator:
    """
    Executes a sequence of tool calls with automatic rollback on failure.
    Implements the Saga Pattern for distributed transactions.
    """
    
    def __init__(self, tracer: ExecutionTracer, tool_registry: dict):
        self.tracer = tracer
        self.tool_registry = tool_registry
        self.successful_steps: list[StepRecord] = []
    
    async def execute(self, steps: list[Step]) -> SagaResult:
        """Execute steps, rolling back on failure."""
        try:
            for step in steps:
                result = await self._execute_step(step)
                self.successful_steps.append(StepRecord(step=step, result=result))
            return SagaResult(status="success", steps=self.successful_steps)
        
        except Exception as e:
            await self._rollback()
            return SagaResult(status="rolled_back", error=str(e))
    
    async def _execute_step(self, step: Step) -> Any:
        """Execute a single step with retries."""
        contract = self.tool_registry[step.tool_name]["contract"]
        retries = contract.get("retries", 0)
        
        for attempt in range(retries + 1):
            try:
                tool_func = self.tool_registry[step.tool_name]["function"]
                return self.tracer.trace_and_execute(tool_func, **step.arguments)
            except Exception as e:
                if attempt < retries:
                    await asyncio.sleep(1)  # Backoff
                else:
                    raise
    
    async def _rollback(self):
        """Execute compensating tools in reverse order."""
        logging.warning("--- INITIATING ROLLBACK ---")
        
        for record in reversed(self.successful_steps):
            tool_name = record.step.tool_name
            contract = self.tool_registry[tool_name]["contract"]
            compensating_tool_name = contract.get("compensating_tool")
            
            if compensating_tool_name and compensating_tool_name in self.tool_registry:
                logging.info(f"Running compensating tool: {compensating_tool_name}")
                comp_func = self.tool_registry[compensating_tool_name]["function"]
                try:
                    self.tracer.trace_and_execute(comp_func, **record.step.arguments)
                except Exception as e:
                    logging.error(f"Compensating tool failed: {e}")
            else:
                logging.warning(f"No compensating tool for {tool_name}")
        
        logging.info("--- ROLLBACK COMPLETE ---")

@dataclass
class Step:
    tool_name: str
    arguments: dict

@dataclass  
class StepRecord:
    step: Step
    result: Any

@dataclass
class SagaResult:
    status: str  # "success" | "rolled_back" | "failed"
    steps: list[StepRecord] = field(default_factory=list)
    error: Optional[str] = None
```

### 4.5 Tool Execution with Tracing (Ported from AgentHelm)

```python
# nexus/core/tracer.py â€” Enhanced from AgentHelm

class ExecutionTracer:
    """Traces tool execution with retry, approval, and cost tracking."""
    
    def __init__(
        self, 
        storage: BaseStorage, 
        approval_handler: ApprovalHandler,
        cost_tracker: CostTracker,
    ):
        self.storage = storage
        self.approval_handler = approval_handler
        self.cost_tracker = cost_tracker
        self._current_context = {}
    
    def trace_and_execute(self, tool_func: Callable, **kwargs) -> Any:
        """Execute a tool with full tracing, retries, and approval."""
        contract = TOOL_REGISTRY.get(tool_func.__name__, {}).get("contract", {})
        
        # 1. Check approval if required
        if contract.get("requires_approval"):
            if not self.approval_handler.request_approval(tool_func.__name__, kwargs):
                raise PermissionError("User did not approve execution.")
        
        # 2. Check cost budget
        if not self.cost_tracker.check_budget(contract.get("max_cost", float("inf"))):
            raise BudgetExceededError("Cost budget exceeded")
        
        # 3. Execute with retries
        retries = contract.get("retries", 0)
        last_error = None
        
        for attempt in range(retries + 1):
            try:
                start_time = time.monotonic()
                result = tool_func(**kwargs)
                execution_time = time.monotonic() - start_time
                
                # 4. Record successful event
                self._record_event(tool_func, kwargs, result, execution_time, attempt)
                return result
                
            except Exception as e:
                last_error = e
                if attempt < retries:
                    time.sleep(1)  # Backoff
        
        # 5. Record failed event
        self._record_event(tool_func, kwargs, None, 0, retries, error=str(last_error))
        raise last_error
```

**Deliverables:**
- `Pipeline` for sequential execution
- `Parallel` for concurrent execution
- `SagaOrchestrator` with automatic rollback (AgentHelm DNA)
- `ExecutionTracer` with retries, approval, and cost tracking
- `Orchestrator` as the main entry point
- Integration tests with rollback scenarios

---

## Week 5: CLI & Tracing

### 5.1 CLI Interface
```python
# nexus/cli.py
import click
from rich.console import Console

@click.group()
def cli():
    """AgentHelm - DSPy Multi-Agent Orchestration Framework"""
    pass

@cli.command()
@click.argument("task")
@click.option("--agents", "-a", multiple=True, help="Agents to use")
def run(task: str, agents: tuple[str]):
    """Run a task with specified agents."""
    ...

@cli.command()
def list_agents():
    """List all available agents."""
    ...

@cli.command()
@click.argument("agent_name")
def describe(agent_name: str):
    """Describe an agent's capabilities."""
    ...
```

### 5.2 OpenTelemetry Integration
```python
# nexus/tracing.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider

class AgentHelmTracer:
    """Wraps OpenTelemetry for AgentHelm-specific tracing."""
    
    def __init__(self, service_name: str = "agenthelm"):
        ...
    
    @contextmanager
    def trace_agent(self, agent: Agent, input: dict):
        """Trace an agent execution."""
        with self.tracer.start_as_current_span(f"agent.{agent.name}") as span:
            span.set_attribute("agent.name", agent.name)
            span.set_attribute("input", json.dumps(input))
            yield span
    
    @contextmanager
    def trace_memory_op(self, op: str, key: str):
        """Trace a memory operation."""
        ...
```

**Deliverables:**
- Full CLI with `run`, `list-agents`, `describe` commands
- OpenTelemetry tracing integrated into agents and memory
- Trace export to console (pretty print) and OTLP

---

## Week 6: Testing, Docs & Polish

### 6.1 Test Suite
```
tests/
â”œâ”€â”€ conftest.py          # Fixtures (mock LLM, memory backends)
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â””â”€â”€ test_orchestration.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_cli.py
â””â”€â”€ e2e/
    â””â”€â”€ test_full_workflow.py
```

**Testing Strategy:**
- Unit tests: Mock DSPy LLM calls, mock Redis/ChromaDB
- Integration tests: Use VCR to record/replay LLM calls
- E2E tests: Full workflow with real (or recorded) LLM

### 6.2 Documentation
```
docs/
â”œâ”€â”€ index.md             # Overview
â”œâ”€â”€ quickstart.md        # 5-minute getting started
â”œâ”€â”€ concepts/
â”‚   â”œâ”€â”€ agents.md
â”‚   â”œâ”€â”€ memory.md
â”‚   â””â”€â”€ orchestration.md
â”œâ”€â”€ tutorials/
â”‚   â”œâ”€â”€ first-agent.md
â”‚   â””â”€â”€ multi-agent-pipeline.md
â””â”€â”€ api/
    â””â”€â”€ reference.md
```

### 6.3 Examples
```
examples/
â”œâ”€â”€ simple_qa/           # Single agent Q&A
â”œâ”€â”€ research_pipeline/   # Multi-agent research workflow
â””â”€â”€ parallel_analysis/   # Parallel agent execution
```

**Deliverables:**
- >80% test coverage
- MkDocs site with all documentation
- 3 working examples
- Release v0.3.0

---

## Verification Plan

### Automated Tests
```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=agenthelm --cov-report=html

# Run specific test categories
uv run pytest tests/unit/
uv run pytest tests/integration/
uv run pytest tests/e2e/
```

### Manual Verification

1. **CLI Smoke Test**
   ```bash
   # List agents
   uv run agenthelm list-agents
   
   # Run a simple task
   uv run agenthelm run "What is the capital of France?" --agents researcher
   
   # Run a pipeline
   uv run agenthelm run "Write a blog post about AI" --agents researcher,writer,reviewer
   ```

2. **Memory Verification**
   ```bash
   # Start Redis
   docker run -d -p 6379:6379 redis:alpine
   
   # Run task, then check Redis for stored context
   uv run agenthelm run "Research quantum computing" --agents researcher
   redis-cli KEYS "agenthelm:*"
   ```

3. **Tracing Verification**
   ```bash
   # Run with tracing enabled
   NEXUS_TRACE=true uv run agenthelm run "Hello world" --agents researcher
   
   # Check console output for trace spans
   # Or send to Jaeger/Zipkin for visualization
   ```

---

## Dependencies on External Systems

| System | Purpose | Setup |
|--------|---------|-------|
| **Redis** | Short-term memory | `docker run -d -p 6379:6379 redis:alpine` |
| **ChromaDB** | Semantic memory | Embedded (no setup needed) |
| **LLM API** | DSPy backend | Set `OPENAI_API_KEY` or `MISTRAL_API_KEY` |

---

## Success Criteria for v0.3.0

### Core Functionality
- [ ] Can define a custom agent in <50 lines of code
- [ ] Can run a 3-agent pipeline from CLI
- [ ] Memory persists across agent calls within a session
- [ ] Semantic search returns relevant results
- [ ] Traces visible in console output
- [ ] All tests passing
- [ ] Documentation site deployed

### AgentHelm DNA Features âœ…
- [ ] **Tool Contracts**: `@tool` decorator registers tools with inputs/outputs/side_effects
- [ ] **Automatic Retries**: Failed tool calls retry based on `retries` contract field
- [ ] **Compensating Actions**: Rollback executes `compensating_tool` in reverse order on failure
- [ ] **Approval Gates**: Tools with `requires_approval=True` prompt for confirmation
- [ ] **Cost Tracking**: LLM calls tracked with token counts and estimated USD cost
- [ ] **Execution Tracing**: Every tool call logged with timestamp, inputs, outputs, reasoning
- [ ] **Storage Backends**: Events persist to JSON (dev) or SQLite (prod)

---

## Component Summary: What's Ported vs New

| Component | Source | Status |
|-----------|--------|--------|
| `@tool` decorator | AgentHelm | **Port** (add `timeout`, `tags`) |
| `TOOL_REGISTRY` | AgentHelm | **Port** (unchanged) |
| `ExecutionTracer` | AgentHelm | **Port** (add cost tracking) |
| `ExecutionEvent` | AgentHelm | **Port** (add token usage, trace_id) |
| `ApprovalHandler` | AgentHelm | **Port** (add webhook handler) |
| `BaseStorage`, `JsonStorage`, `SqliteStorage` | AgentHelm | **Port** (unchanged) |
| Saga/Rollback logic | AgentHelm `agent.py` | **Port** (extract to `SagaOrchestrator`) |
| `CostTracker`, `TokenUsage` | â€” | **NEW** |
| `Agent` (DSPy base) | â€” | **NEW** |
| `MemoryHub`, `MemoryContext` | â€” | **NEW** |
| `ShortTermMemory`, `SemanticMemory` | â€” | **NEW** |
| `Pipeline`, `Parallel`, `Orchestrator` | â€” | **NEW** |
| CLI (`agenthelm`) | â€” | **NEW** |
| OpenTelemetry integration | â€” | **NEW** |

---

## What's Next (Phase 2 Preview)

After v0.3.0, Phase 2 focuses on **Protocol Support**:
- MCP server (expose agents as tools)
- MCP client (consume external tools)
- A2A messaging between agents
- Inter-process agent communication

---

*Plan last updated: December 2025*

